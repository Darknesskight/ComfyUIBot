{
  "100": {
    "inputs": {
      "ckpt_name": {{model | tojson}}
    },
    "class_type": "CheckpointLoaderSimple"
  },
  {% for lora in loras %}
  "{{loop.index + 100}}": {
    "inputs": {
      "lora_name": {{lora.name | tojson}},
      "strength_model": {{lora.strength}},
      "strength_clip": {{lora.strength}},
      "model": [
        "{{loop.index + 99}}",
        0
      ],
      "clip": [
        "{{loop.index + 99}}",
        1
      ]
    },
    "class_type": "LoraLoader"
  },
  {% endfor %}
  "3": {
    "inputs": {
      "seed": {{ seed }},
      "steps": {{ steps }},
      "cfg": {{ cfg }},
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "11",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "5",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "5": {
    "inputs": {
      "width": {{width}},
      "height": {{height}},
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage"
  },
  "6": {
    "inputs": {
      "text": {{prompt | tojson}},
      "clip": [
        "9",
        0
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "7": {
    "inputs": {
      "text": {{negative_prompt | tojson}},
      "clip": [
        "9",
        0
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "8": {
    "inputs": {
      "vae_name": "sd-1.5\\kl-f8-anime2.ckpt.vae.pt"
    },
    "class_type": "VAELoader"
  },
  "9": {
    "inputs": {
      "stop_at_clip_layer": -2,
      "clip": [
        "{{loras | length + 100}}",
        1
      ]
    },
    "class_type": "CLIPSetLastLayer"
  },
  "11": {
    "inputs": {
      "ratio": 0.3,
      "model": [
        "{{loras | length + 100}}",
        0
      ]
    },
    "class_type": "TomePatchModel"
  },
  {% if hires is not none %}
  "13": {
    "inputs": {
      "upscale_method": {{hires | tojson }},
      "width": {{hires_width}},
      "height": {{hires_height}},
      "crop": "disabled",
      "samples": [
        "3",
        0
      ]
    },
    "class_type": "LatentUpscale"
  },
  "14": {
    "inputs": {
      "seed": {{ seed }},
      "steps": 15,
      "cfg": {{ cfg }},
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": {{ hires_strength }},
      "model": [
        "11",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "13",
        0
      ]
    },
    "class_type": "KSampler"
  },
  {% endif %}
  "10": {
    "inputs": {
      {% if hires is not none %}
      "samples": [
        "14",
        0
      ],
      {% else %}
      "samples": [
        "3",
        0
      ],
      {% endif %}
      "vae": [
        "8",
        0
      ]
    },
    "class_type": "VAEDecode"
  },
  "12": {
    "inputs": {
      "images": [
        "10",
        0
      ]
    },
    "class_type": "PreviewImage"
  }
}